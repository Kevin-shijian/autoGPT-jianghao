{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bjrLvs6I-I4JgdZny7g9Ev3pgjfyRkP2",
      "authorship_tag": "ABX9TyMXLGCwwZAtPBNAdO59c/Xz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acl-jianghao/Langchain-demos/blob/main/07_sequentialChain_tools_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OYxEk1iYV00",
        "outputId": "805a5a0d-782b-4d67-cbd2-aca005b90806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m963.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq openai langchain tiktoken colab-env pymupdf faiss-cpu google-search-results\n",
        "!pip install -Uqq pyspark-ai pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import colab_env"
      ],
      "metadata": {
        "id": "7kIf99hdb41Z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.agents import load_tools\n",
        "\n",
        "# tools = load_tools([\"serpapi\"])\n",
        "# tools.append()"
      ],
      "metadata": {
        "id": "J5hGq-YzvMZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.utilities import SerpAPIWrapper\n",
        "\n",
        "# search = SerpAPIWrapper()\n",
        "\n",
        "# search.run(\"what is the weather of Hangzhou of next 7 days?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ooTi65hV4jDM",
        "outputId": "e0a79791-6140-4723-9a04-fee2863f1b2d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Precipitation: Rain: 0.01 Snow: 0. Precipitation Chance: 11%. E. Wind: 7 mph. Jul 24 – Jul 30Jul 31 – Aug 6Aug 7 – Aug 13. See weather overview ...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "serpapi_api_key = os.getenv('SERPAPI_API_KEY')"
      ],
      "metadata": {
        "id": "xB6Kb-zD7HCH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import load_tools, initialize_agent\n",
        "\n",
        "\n",
        "# llm=ChatOpenAI(temperature=0, verbose=True)\n",
        "llm=OpenAI(temperature=0, verbose=True)\n",
        "# tools = load_tools([\"serpapi\"], llm, serpapi_api_key=serpapi_api_key)\n",
        "# agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "# result = agent.run(\"please list the weather of each day in Hangzhou of the next 7 days?\")"
      ],
      "metadata": {
        "id": "oycs_kjb4_uQ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "\n",
        "\n",
        "# Prompt templates\n",
        "serp_template = PromptTemplate(\n",
        "    input_variables = ['city'],\n",
        "    template=\"\"\"Please list the weather, temperature and air quality of each day in {city} of\n",
        "            the next 7 days and response should be a string in code block\"\"\"\n",
        ")\n",
        "\n",
        "tell_template = PromptTemplate(\n",
        "    input_variables = ['string'],\n",
        "    template=\"\"\"Tell me the average temperature in {string},\n",
        "            the answer should only have the average temperature in Chinese \"\"\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Nvg3oyV084G1"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_chain = LLMChain(llm=llm, prompt=serp_template, verbose=False, output_key='string')\n",
        "tell_chain = LLMChain(llm=llm, prompt=tell_template, verbose=False, output_key='average_temperature')\n",
        "\n",
        "\n",
        "sequential_chain = SequentialChain(\n",
        "    chains = [weather_chain, tell_chain],\n",
        "    input_variables=['city'],\n",
        "    output_variables=['string', 'average_temperature'],\n",
        "    verbose=True)\n",
        "\n",
        "# sequential_chain = SequentialChain(\n",
        "#     chains = [weather_chain],\n",
        "#     input_variables=['city'],\n",
        "#     output_variables=['json'],\n",
        "#     verbose=True)"
      ],
      "metadata": {
        "id": "lVIj7No7BCjo"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequential_chain('Hangzhou')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQo-mNZR-lcs",
        "outputId": "c33eb0f8-1f4a-4e20-95a9-a08003b2a083"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': 'Hangzhou',\n",
              " 'string': '\\n\\nDay 1: Weather: Sunny, Temperature: 25°C, Air Quality: Good\\nDay 2: Weather: Cloudy, Temperature: 22°C, Air Quality: Moderate\\nDay 3: Weather: Rainy, Temperature: 20°C, Air Quality: Poor\\nDay 4: Weather: Partly Cloudy, Temperature: 23°C, Air Quality: Good\\nDay 5: Weather: Sunny, Temperature: 25°C, Air Quality: Moderate\\nDay 6: Weather: Cloudy, Temperature: 22°C, Air Quality: Poor\\nDay 7: Weather: Partly Cloudy, Temperature: 24°C, Air Quality: Good',\n",
              " 'average_temperature': '\\n\\n平均温度：22.7°C'}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark_ai import SparkAI\n",
        "\n",
        "# spark_ai = SparkAI(llm=llm, verbose=True)\n",
        "\n",
        "# spark_ai.activate()\n"
      ],
      "metadata": {
        "id": "I1jTSVJdDirz"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tools + agent"
      ],
      "metadata": {
        "id": "Aff2YZ5JQXfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools, initialize_agent\n",
        "\n",
        "tools = load_tools([\"serpapi\"], llm, serpapi_api_key=serpapi_api_key)\n",
        "\n",
        "\n",
        "# agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "# result = agent.run(\"please list the weather of each day in Hangzhou of the next 7 days?\")"
      ],
      "metadata": {
        "id": "oK50PXu-GLw6"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool\n",
        "\n",
        "class CalculateAverage(BaseTool):\n",
        "    name = \"Calculate Average\"\n",
        "    description = 'use this tool to calculate the average value.'\n",
        "\n",
        "    def _run(self, expr: str):\n",
        "        return 10.1\n",
        "\n",
        "    def _arun(self, query: str):\n",
        "        raise NotImplementedError(\"Async function is not ready yet\")\n",
        "\n",
        "# tools.append(CalculateAverage())\n",
        "\n",
        "\n",
        "tools"
      ],
      "metadata": {
        "id": "WAq1thh2N_Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "agent.run(\"please tell me the temprature average of Hangzhou in the next 7 days?\")\n",
        "\n",
        "# agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "# agent.run(\"please list the weather of each day in Hangzhou of the next 7 days?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "P4o1thWoIDY-",
        "outputId": "b58ed3e8-a97d-4e05-fc9d-b2065889c2ea"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find the average temperature of Hangzhou in the next 7 days\n",
            "Action: Search\n",
            "Action Input: \"Hangzhou temperature forecast 7 days\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m2 Week Extended Forecast in Hangzhou, Zhejiang, China ; 85 / 78 °F · 85 / 78 °F · 87 / 79 °F ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the average temperature\n",
            "Action: Calculate Average\n",
            "Action Input: 85 / 78 °F · 85 / 78 °F · 87 / 79 °F ...\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m10.1\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The average temperature of Hangzhou in the next 7 days is 10.1°F.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The average temperature of Hangzhou in the next 7 days is 10.1°F.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gmail toolkit: https://python.langchain.com/docs/integrations/toolkits/gmail"
      ],
      "metadata": {
        "id": "9_AUYq-nfBAb"
      }
    }
  ]
}