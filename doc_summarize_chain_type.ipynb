{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWSstjkFggFosStJ6Sr3is",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acl-jianghao/Langchain-Scripts/blob/main/doc_summarize_chain_type.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load PDF by URL\n",
        "- langchai: summarize\n",
        "- The differency of 'chain_type'\n",
        "- Openai:text-davinci-003 and ChatOpenai:gpt-3.5-turbo-16k"
      ],
      "metadata": {
        "id": "MglQolT88YwV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhkbvCutsnxE"
      },
      "outputs": [],
      "source": [
        "%pip install openai -qU\n",
        "%pip install langchain -qU\n",
        "%pip install tiktoken -qU\n",
        "%pip install colab-env -qU\n",
        "%pip install pypdf -qU\n",
        "%pip install unstructured -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import colab_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cArL47rNtkGA",
        "outputId": "79f4fed5-069a-48aa-9309-ab68a836f634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.document_loaders import OnlinePDFLoader"
      ],
      "metadata": {
        "id": "x_ZFaWc5tnH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#online document\n",
        "\n",
        "loader = OnlinePDFLoader('https://arxiv.org/pdf/2307.11278',)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2q5VPSvt8ti",
        "outputId": "c447e83f-acc8-4f62-a564-9237e41f7c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"There are %s document(s).\"% len(docs))\n",
        "print(\"There are %s characters in first document(page).\" % len(docs[0].page_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLM-5SROvA3T",
        "outputId": "598396da-3cb4-46db-8c05-ca56657421e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 document(s).\n",
            "There are 70725 characters in first document(page).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "split_docs = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "WcAVJosvpXFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "#openai completion api"
      ],
      "metadata": {
        "id": "uX0VBl4aoOyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#alternative way to spicify 'openai_api_key'\n",
        "openai.api_key=os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "AvGTTisDqvtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# playground: https://platform.openai.com/playground/p/default-summarize?mode=complete\n",
        "# Openai token limit 4097\n",
        "llm = OpenAI(temperature=0, model_name='text-davinci-003')\n",
        "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)"
      ],
      "metadata": {
        "id": "S_VvBdyWoc2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stuff:\n",
        "- Step1: PDF -> {prompt, doc} -> OpenAI\n",
        "- Step2: OpenAI -> {doc_summary}\n",
        "\n",
        "map_reduce:\n",
        "- Step1: PDF -> [{doc_chunk(1), doc_chunk(2), ...}]\n",
        "- Step2: [{prompt, doc_chunk(1)}, {prompt, doc_chunk(2)}, ...] -> OpenAI\n",
        "- Step3: OpenAI -> [{chunk_summary(1)}, {chunk_summary(2)}, ...]\n",
        "- Step4: [{chunk_summary(1)}, {chunk_summary(2)}, ...] -> OpenAI -> {doc_summary(the_summary_of_summary(1..n))}\n",
        "\n",
        "refine\n",
        "- Step1: PDF -> [{doc_chunk(1), doc_chunk(2), ...}]\n",
        "- Step2: {prompt, doc_chunk(1)} -> OpenAI -> {chunk_summary(1)}\n",
        "- Step3: {prompt, {chunk_summary(1), doc_chunk(2)}} -> OpanAI -> {chunk_summary(1_2)}\n",
        "- ...\n",
        "- StepN: {doc_summary(chunk_summary(1_n))}\n",
        "\n",
        "map_rerank\n",
        "- Step1: PDF -> [{doc_chunk(1), doc_chunk(2), ...}]\n",
        "- Step2: {prompt, doc_chunk(1)} -> OpenAI -> {chunk_summary(1), rank_score(1)}\n",
        "- ...\n",
        "- StepN: {doc_summary(chunk_summary(k), highest_rank_score(k))}"
      ],
      "metadata": {
        "id": "Z775-gH2wkq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=split_docs)"
      ],
      "metadata": {
        "id": "T4tO0x7yvTSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpt-3.5-turbo-16k"
      ],
      "metadata": {
        "id": "dx_rhbe54FCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " content = \"\"\n",
        " for s in split_docs[:70]:\n",
        "    content += s.page_content + \"\\n\""
      ],
      "metadata": {
        "id": "OnE0Ch0m53pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "refer to: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "- https://platform.openai.com/tokenizer"
      ],
      "metadata": {
        "id": "p17hGmQw8PsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo-16k')\n",
        "encoding_davinci = tiktoken.encoding_for_model('text-davinci-003')"
      ],
      "metadata": {
        "id": "ApsNPD2H63Hu"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(content))\n",
        "print(len(encoding.encode(content)))\n",
        "print(len(encoding_davinci.encode(content)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWl4oVYj7ZrZ",
        "outputId": "900b3c32-1e00-42ee-fbf6-b551a7db0446"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53069\n",
            "13847\n",
            "14040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "# llm = OpenAI(temperature=0, model_name='text-davinci-003')\n",
        "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-16k', verbose=False)\n",
        "chain = load_summarize_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "2SVHByzk280B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=split_docs[:70])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "S7HYdLFj4ejs",
        "outputId": "82926ac6-afe1-405a-a47d-2c70f473952c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The paper proposes a novel approach called Generator-Retriever-Generator (GRG) for open-domain question answering. The approach combines document retrieval techniques with large language models to generate informative and contextually relevant answers. The GRG approach outperforms existing baseline models on benchmark datasets, demonstrating its effectiveness in improving question answering accuracy. The paper also includes an ablation study and provides detailed implementation details and experimental results.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}